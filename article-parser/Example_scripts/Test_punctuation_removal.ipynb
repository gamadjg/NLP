{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adolescent-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "sent_token_array = []\n",
    "sent_token_array_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pharmaceutical-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tacos are some of the best forms of food.',\n",
       " 'They are simple, meat wrapped in a tortilla, with some toppings on it.',\n",
       " 'To me it comes down to fundamentals, because the taco is simple it forces cooks to really know what they are doing with no frills.',\n",
       " \"One's ability to cook the tortilla, the meat, which toppings to choose, every little thing counts.\",\n",
       " 'Tacos are some of the best forms of food.',\n",
       " 'They are simple, meat wrapped in a tortilla, with some toppings on it.',\n",
       " 'To me it comes down to fundamentals, because the taco is simple it forces cooks to really know what they are doing with no frills.',\n",
       " \"One's ability to cook the tortilla, the meat, which toppings to choose, every little thing counts.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the txt file, read contents, tokenize each sentence, store each token in an array\n",
    "with open('../Articles/article-1.txt', 'r') as f:\n",
    "    sent_tokens = sent_tokenize(f.read())\n",
    "    for line in sent_tokens:\n",
    "        sent_token_array.append(line)\n",
    "sent_token_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "varying-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 test.\n"
     ]
    }
   ],
   "source": [
    "def multiple_replace(text):\n",
    "    dict = {\n",
    "    \",\" : \"\",\n",
    "    \"\\\\.\" : \"\\n\",\n",
    "    \"?\" : \"\\n\",\n",
    "    }\n",
    "    # Create a regular expression  from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "#if __name__ == \"__main__\": \n",
    "\n",
    "#text = \"Larry Wall is the creator of Perl\"\n",
    "\n",
    "#print(multiple_replace('1.25, test.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aboriginal-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1.25', 'test']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "test = '1.25, test.'\n",
    "new_sent = re.sub(r'\\.$|[?!]','\\n', test)\n",
    "new_sent = re.sub(r',','', new_sent)\n",
    "print(new_sent)\n",
    "new_sent = word_tokenize(new_sent)\n",
    "new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "combined-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tacos', 'are', 'some', 'of', 'the', 'best', 'forms', 'of', 'food', '.'],\n",
       " ['they',\n",
       "  'are',\n",
       "  'simple',\n",
       "  ',',\n",
       "  'meat',\n",
       "  'wrapped',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tortilla',\n",
       "  ',',\n",
       "  'with',\n",
       "  'some',\n",
       "  'toppings',\n",
       "  'on',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['to',\n",
       "  'me',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'down',\n",
       "  'to',\n",
       "  'fundamentals',\n",
       "  ',',\n",
       "  'because',\n",
       "  'the',\n",
       "  'taco',\n",
       "  'is',\n",
       "  'simple',\n",
       "  'it',\n",
       "  'forces',\n",
       "  'cooks',\n",
       "  'to',\n",
       "  'really',\n",
       "  'know',\n",
       "  'what',\n",
       "  'they',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'with',\n",
       "  'no',\n",
       "  'frills',\n",
       "  '.'],\n",
       " ['one',\n",
       "  \"'s\",\n",
       "  'ability',\n",
       "  'to',\n",
       "  'cook',\n",
       "  'the',\n",
       "  'tortilla',\n",
       "  ',',\n",
       "  'the',\n",
       "  'meat',\n",
       "  ',',\n",
       "  'which',\n",
       "  'toppings',\n",
       "  'to',\n",
       "  'choose',\n",
       "  ',',\n",
       "  'every',\n",
       "  'little',\n",
       "  'thing',\n",
       "  'counts',\n",
       "  '.'],\n",
       " ['tacos', 'are', 'some', 'of', 'the', 'best', 'forms', 'of', 'food', '.'],\n",
       " ['they',\n",
       "  'are',\n",
       "  'simple',\n",
       "  ',',\n",
       "  'meat',\n",
       "  'wrapped',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tortilla',\n",
       "  ',',\n",
       "  'with',\n",
       "  'some',\n",
       "  'toppings',\n",
       "  'on',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['to',\n",
       "  'me',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'down',\n",
       "  'to',\n",
       "  'fundamentals',\n",
       "  ',',\n",
       "  'because',\n",
       "  'the',\n",
       "  'taco',\n",
       "  'is',\n",
       "  'simple',\n",
       "  'it',\n",
       "  'forces',\n",
       "  'cooks',\n",
       "  'to',\n",
       "  'really',\n",
       "  'know',\n",
       "  'what',\n",
       "  'they',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'with',\n",
       "  'no',\n",
       "  'frills',\n",
       "  '.'],\n",
       " ['one',\n",
       "  \"'s\",\n",
       "  'ability',\n",
       "  'to',\n",
       "  'cook',\n",
       "  'the',\n",
       "  'tortilla',\n",
       "  ',',\n",
       "  'the',\n",
       "  'meat',\n",
       "  ',',\n",
       "  'which',\n",
       "  'toppings',\n",
       "  'to',\n",
       "  'choose',\n",
       "  ',',\n",
       "  'every',\n",
       "  'little',\n",
       "  'thing',\n",
       "  'counts',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the sentence tokens into word tokens\n",
    "word_tokens = [[w.lower() for w in word_tokenize(text)] for text in sent_token_array]\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formal-premiere",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1bd720b0d7ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'... some string with punctuation ...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import string\n",
    "s = '... some string with punctuation ...'\n",
    "s = s.translate(None)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-trade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
